{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59436c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configure your PATH here\n",
    "PATH = \"C:\\\\Users\\\\PC\\\\Desktop\\\\Web Scrape Project\\\\chromedriver.exe\"\n",
    "wb = webdriver.Chrome(PATH)\n",
    "\n",
    "def get_images_from_google(wb, delay, max_images):\n",
    "    def scroll_down(wb):\n",
    "        wb.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    url = \"https://www.google.com/search?q=cats&tbm=isch&ved=2ahUKEwjykJ779tbzAhXhgnIEHSVQBksQ2-cCegQIABAA&oq=cats&gs_lcp=CgNpbWcQAzIHCAAQsQMQQzIHCAAQsQMQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzoHCCMQ7wMQJ1C_31NYvOJTYPbjU2gCcAB4AIABa4gBzQSSAQMzLjOYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&sclient=img&ei=7vZuYfLhOeGFytMPpaCZ2AQ&bih=817&biw=1707&rlz=1C1CHBF_enCA918CA918\"\n",
    "    wb.get(url)\n",
    "    \n",
    "    image_urls = set()\n",
    "    \n",
    "    # Using the class name \"Q4LuWd\" to identify the thumbnails\n",
    "    thumbnails = wb.find_elements(By.CLASS_NAME, \"Q4LuWd\")  \n",
    "    \n",
    "    for img in thumbnails:\n",
    "        try:\n",
    "            img.click()\n",
    "            time.sleep(delay)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # After clicking on the thumbnail, we try to fetch the larger image's URL\n",
    "        active_image = wb.find_element(By.CSS_SELECTOR, \"img[src^='http']\")\n",
    "        if active_image:\n",
    "            src = active_image.get_attribute('src')\n",
    "            if src:\n",
    "                image_urls.add(src)\n",
    "                print(f\"Found {len(image_urls)}\")\n",
    "                if len(image_urls) >= max_images:\n",
    "                    return image_urls\n",
    "    \n",
    "    return image_urls\n",
    "\n",
    "def download_image(download_path, url, file_name):\n",
    "    try:\n",
    "        # Ensure the directory exists\n",
    "        if not os.path.exists(download_path):\n",
    "            os.makedirs(download_path)\n",
    "        \n",
    "        image_content = requests.get(url).content\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file)\n",
    "        \n",
    "        # Dynamically determine the image format\n",
    "        file_format = image.format\n",
    "        file_path = os.path.join(download_path, file_name + \".\" + file_format.lower())\n",
    "        \n",
    "        with open(file_path, \"wb\") as f:\n",
    "            image.save(f, file_format)\n",
    "            \n",
    "        print(\"Success\")\n",
    "    except Exception as e:\n",
    "        print(f'FAILED to download {url} - ', e)\n",
    "\n",
    "urls = get_images_from_google(wb, 1, 2)\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    download_image(\"imgs/\", url, str(i))\n",
    "\n",
    "wb.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb5361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# import io\n",
    "# from PIL import Image\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "# # Configure your PATH here\n",
    "# PATH = \"C:\\\\Users\\\\PC\\\\Desktop\\\\Web Scrape Project\\\\chromedriver.exe\"\n",
    "\n",
    "# # Setting up the user agent\n",
    "# chrome_options = Options()\n",
    "# user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "# chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "# wb = webdriver.Chrome(PATH, options=chrome_options)\n",
    "\n",
    "# def get_images_from_google(wb, delay, max_images):\n",
    "#     def scroll_down(wb):\n",
    "#         wb.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "#         time.sleep(delay)\n",
    "    \n",
    "#     url = \"https://www.google.com/search?q=cats&tbm=isch&ved=2ahUKEwjykJ779tbzAhXhgnIEHSVQBksQ2-cCegQIABAA&oq=cats&gs_lcp=CgNpbWcQAzIHCAAQsQMQQzIHCAAQsQMQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzIECAAQQzoHCCMQ7wMQJ1C_31NYvOJTYPbjU2gCcAB4AIABa4gBzQSSAQMzLjOYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&sclient=img&ei=7vZuYfLhOeGFytMPpaCZ2AQ&bih=817&biw=1707&rlz=1C1CHBF_enCA918CA918\"\n",
    "#     wb.get(url)\n",
    "    \n",
    "#     image_urls = set()\n",
    "    \n",
    "#     # Using the class name \"Q4LuWd\" to identify the thumbnails\n",
    "#     thumbnails = wb.find_elements(By.CLASS_NAME, \"Q4LuWd\")  \n",
    "    \n",
    "#     for img in thumbnails:\n",
    "#         try:\n",
    "#             img.click()\n",
    "#             time.sleep(delay)\n",
    "#         except:\n",
    "#             continue\n",
    "        \n",
    "#         # After clicking on the thumbnail, we try to fetch the larger image's URL\n",
    "#         active_image = wb.find_element(By.CSS_SELECTOR, \"img[src^='http']\")\n",
    "#         if active_image:\n",
    "#             src = active_image.get_attribute('src')\n",
    "#             if src:\n",
    "#                 image_urls.add(src)\n",
    "#                 print(f\"Found {len(image_urls)}\")\n",
    "#                 if len(image_urls) >= max_images:\n",
    "#                     return image_urls\n",
    "    \n",
    "#     return image_urls\n",
    "\n",
    "# def download_image(download_path, url, file_name):\n",
    "#     try:\n",
    "#         # Ensure the directory exists\n",
    "#         if not os.path.exists(download_path):\n",
    "#             os.makedirs(download_path)\n",
    "        \n",
    "#         image_content = requests.get(url).content\n",
    "#         image_file = io.BytesIO(image_content)\n",
    "#         image = Image.open(image_file)\n",
    "        \n",
    "#         # Dynamically determine the image format\n",
    "#         file_format = image.format\n",
    "#         file_path = os.path.join(download_path, file_name + \".\" + file_format.lower())\n",
    "        \n",
    "#         with open(file_path, \"wb\") as f:\n",
    "#             image.save(f, file_format)\n",
    "            \n",
    "#         print(\"Success\")\n",
    "#     except Exception as e:\n",
    "#         print(f'FAILED to download {url} - ', e)\n",
    "\n",
    "# urls = get_images_from_google(wb, 1, 6)\n",
    "\n",
    "# for i, url in enumerate(urls):\n",
    "#     download_image(\"imgs/\", url, str(i))\n",
    "\n",
    "# wb.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ef39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# import io\n",
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# # Configure your PATH here\n",
    "# PATH = \"C:\\\\Users\\\\PC\\\\Desktop\\\\Web Scrape Project\\\\chromedriver.exe\"\n",
    "\n",
    "# # Setting up headless browser and eager load strategy\n",
    "# chrome_options = Options()\n",
    "# chrome_options.headless = True\n",
    "# chrome_options.page_load_strategy = 'eager'\n",
    "\n",
    "# wb = webdriver.Chrome(PATH, options=chrome_options)\n",
    "\n",
    "# def get_images_from_google(wb, max_images):\n",
    "#     url = \"https://www.google.com/search?q=cats&tbm=isch\"\n",
    "#     wb.get(url)\n",
    "    \n",
    "#     image_urls = set()\n",
    "    \n",
    "#     # Using the class name \"Q4LuWd\" to identify the thumbnails\n",
    "#     thumbnails = WebDriverWait(wb, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"Q4LuWd\")))\n",
    "    \n",
    "#     for img in thumbnails:\n",
    "#         try:\n",
    "#             src = img.find_element(By.CSS_SELECTOR, \"img\").get_attribute(\"src\")\n",
    "#             if src:\n",
    "#                 image_urls.add(src)\n",
    "#                 if len(image_urls) >= max_images:\n",
    "#                     return image_urls\n",
    "#         except:\n",
    "#             continue\n",
    "            \n",
    "#     return image_urls\n",
    "\n",
    "# with requests.Session() as session:  # Using session for persistence\n",
    "#     def download_image(download_path, url, file_name):\n",
    "#         try:\n",
    "#             # Ensure the directory exists\n",
    "#             if not os.path.exists(download_path):\n",
    "#                 os.makedirs(download_path)\n",
    "\n",
    "#             image_content = session.get(url).content  # Using session.get() for persistence\n",
    "#             image_file = io.BytesIO(image_content)\n",
    "#             image = Image.open(image_file)\n",
    "\n",
    "#             # Dynamically determine the image format\n",
    "#             file_format = image.format\n",
    "#             file_path = os.path.join(download_path, file_name + \".\" + file_format.lower())\n",
    "\n",
    "#             with open(file_path, \"wb\") as f:\n",
    "#                 image.save(f, file_format)\n",
    "\n",
    "#             print(f\"Image {file_name} saved successfully.\")\n",
    "#         except Exception as e:\n",
    "#             print(f'FAILED to download {url} - ', e)\n",
    "\n",
    "# urls = get_images_from_google(wb, 6)\n",
    "\n",
    "# for i, url in enumerate(urls):\n",
    "#     download_image(\"/mnt/data/imgs/\", url, str(i))\n",
    "\n",
    "# wb.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185838d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
